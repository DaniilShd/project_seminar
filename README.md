**Название проекта: DINOv2 Дистилляция для классификации дефектов**

**Краткое описание**  
Этот репозиторий содержит минимально жизнеспособный прототип (MVP) исследовательского пайплайна. Пайплайн реализует полный цикл эксперимента для проверки гипотезы о повышении эффективности классификации промышленных дефектов с помощью комбинации self-supervised модели DINOv2 и дистилляции знаний. Решение представляет собой последовательность из семи скриптов, которые автоматизируют загрузку данных, предобработку, извлечение признаков, обучение и сравнительный анализ различных моделей-классификаторов.

**Описание датасета**  
Датасет предназначен для классификации дефектов стальных листов и состоит из изображений поверхности стали с разметкой. Всего 4 класса (ClassId: 1, 2, 3, 4). Разметка представлена в формате сжатия RLE (кодирование длин серий), где для каждого дефекта указан его класс и маска пикселей.

**Разбиение данных и валидация**  

В пайплайне реализовано строго фиксированное стратифицированное разбиение данных 80/20 с использованием единого случайного зерна `random_state=42` для обеспечения полной воспроизводимости. Все модели обучаются на 80% данных и тестируются на оставшихся 20%. Ключевой параметр `stratify=labels` гарантирует сохранение распределения четырех классов дефектов в обеих выборках.

```python
    # Единое разбиение для всех моделей
    X_train, X_test, y_train, y_test = train_test_split(
        features, labels, test_size=0.2, random_state=42, stratify=labels
    )
```

Аналогичное разбиение применяется к SSL-признакам, что обеспечивает статистическую сопоставимость:
```python
    X_train_ssl, X_test_ssl, y_train_ssl, y_test_ssl = train_test_split(
        features_ssl, labels_ssl, test_size=0.2, random_state=42, stratify=labels_ssl
    )
```

В рамках этого подхода: Logistic Regression (Original), Neural Network (Teacher) и дистиллированный Tiny Student обучаются на 80% исходных признаков DINOv2, а Logistic Regression (SSL) — на 80% SSL-признаков. Все модели оцениваются на соответствующих тестовых выборках (20%). Важно отметить, что SSL-модель тестируется на отдельном наборе SSL-признаков, но созданном с идентичными параметрами, что обеспечивает корректность сравнения "улучшения" относительно базовой логистической регрессии. Отсутствие отдельной валидационной выборки и разбиение на уровне патчей (а не целых изображений) являются осознанными упрощениями для исследовательского прототипа, не снижающими воспроизводимость при фиксированном `random_state=42`.

**Скриншоты демонстрации**  
В ходе работы пайплайна генерируются следующие ключевые визуализации:  
_Визуализация bounding boxes, извлеченных из RLE-разметки (шаг 1)._
![alt text](readme_images/0002cc93b.jpg_annotated.png)
![alt text](readme_images/0007a71bf.jpg_annotated.png) 

_Пример вырезанного патча дефекта с контекстом (шаг 2)._
![alt text](readme_images/5bcc61d96_extraction.png)
![alt text](readme_images/b1d3f12b6_extraction.png)

_PCA-проекция признаков, извлеченных предобученной DINOv2 (шаг 3)._
![alt text](readme_images/features_pca.png)

_PCA-проекция признаков после SSL-дообучения DINOv2 (шаг 5)._
![alt text](readme_images/ssl_features_pca.png)

_Совмещенные матрицы ошибок (Confusion Matrix) всех финальных моделей (шаг 7)._
![alt text](readme_images/all_confusion_matrices.png)


**Инструкция по установке и запуску**

1.  **Настройка Kaggle API:** Для скачивания датасета необходимо:
    
    *   Зарегистрироваться на [Kaggle](https://www.kaggle.com/).
        
    *   Создать API токен в настройках профиля (файл `kaggle.json`).
        
    *   Разместить его в локальной директории:
        
        ```bash
        git clone https://github.com/DaniilShd/project_seminar.git
        cd project_seminar
        pip install -r requirements.txt
        ```
        
2.  **Установка зависимостей:**
    
    ```bash
    
    git clone https://github.com/DaniilShd/project\_seminar.git
    cd project\_seminar
    pip install \-r requirements.txt
    ```
3.  **Последовательный запуск пайплайна:**  
    Все глобальные переменные (пути, гиперпараметры) хранятся в `config.yaml`.
    
    *   **Шаг 0: Скачивание датасета.** Выполните `python 00_download_data.py`. Скрипт скачает датасет, распакует его в рабочую директорию `dataset/` и удалит архив.
        
    *   **Шаг 1: Подготовка данных.** Запустите `python 01_prepare_data.py`. Скрипт преобразует разметку из формата RLE в JSON-аннотации с bounding boxes, декодируя маски для разных классов дефектов.
        
    *   **Шаг 2: Извлечение патчей.** Запустите `python 02_extract_patches.py`. Скрипт вырезает квадратные патчи фиксированного размера вокруг обнаруженных дефектов с дополнительным контекстом и сохраняет их для обучения.
        
    *   **Шаг 3: Извлечение базовых признаков.** Запустите `python 03_extract_features_dino.py`. Скрипт извлекает эмбеддинги (признаки) из патчей с помощью предобученной модели DINOv2 и визуализирует их распределение через PCA.
        
    *   **Шаг 4: SSL-дообучение.** Запустите `python 04_ssl_dino_finetune.py`. Скрипт дообучает DINOv2 с помощью self-supervised обучения на патчах для улучшения представлений.
        
    *   **Шаг 5: Извлечение SSL-признаков.** Запустите `python 05_extract_ssl_dino.py` для извлечения признаков с помощью дообученной модели и их PCA-визуализации.PCA-визуализация — это метод визуализации многомерных данных, при котором для отображения на плоскости (2D) используются первые главные компоненты, полученные с помощью метода главных компонент (PCA — Principal Component Analysis).
        
    *   **Шаг 6: Обучение моделей.** Запустите `python 06_train_models.py`. Скрипт обучает четыре модели: линейный классификатор на исходных признаках, нейросеть-учитель, дистиллированную нейросеть-студента и линейный классификатор на SSL-признаках.
        
    *   **Шаг 7: Сравнение и анализ.** Запустите `python 07_compare_models.py`. Скрипт сравнивает производительность всех моделей, вычисляет метрики и генерирует итоговые отчеты.
        

**Список используемых пакетов**  
Основные зависимости перечислены в `requirements.txt`: torch, torchvision, scikit-learn, opencv-python, pandas, numpy, matplotlib, seaborn, pyyaml, kaggle.

**Лицензия**  
Проект распространяется под лицензией Apache License 2.0, которая предоставляет широкие права на использование, модификацию и распространение программного обеспечения, включая коммерческое применение.

**Ссылка на презентацию**  
Презентация по проекту доступна в репозитории: `report/presentation.pdf`.

* * *

### Результаты и выводы

После выполнения пайплайна генерируется сводная таблица метрик:

| Model                               | Parameters | Accuracy | Inference Time | Compression | Improvement                       | Precision | Recall | F1-Score |
|-------------------------------------|------------|----------|----------------|-------------|-----------------------------------|-----------|--------|----------|
| Logistic Regression (Original)      | 1540       | 92.23%   | 1.50ms         | NaN         | NaN                               | 0.923     | 0.922  | 0.922    |
| Neural Network (Teacher)            | 57796      | 94.32%   | 41.13ms        | NaN         | NaN                               | 0.944     | 0.943  | 0.943    |
| Tiny Student (Distilled)            | 26852      | 93.77%   | 530.96µs       | 2.2x        | -0.55% (vs Teacher)               | 0.937     | 0.938  | 0.937    |
| Logistic Regression (SSL Finetuned) | 1540       | 92.49%   | 3.08ms         | NaN         | +0.26% (vs Logistic Regression)   | 0.925     | 0.925  | 0.925    |


**Выводы на основании результатов:**

1.  **Высокое качество признаков DINOv2:** Точность базового линейного классификатора (92.23%) подтверждает, что самоконтролируемая модель DINOv2 извлекает мощные семантические признаки, пригодные для решения задачи "из коробки".
    
2.  **Эффективность дистилляции знаний:** Дистиллированная модель-ученик демонстрирует выдающийся баланс. Она сохраняет **99.4% точности** модели-учителя (падение всего на 0.55%), при этом имея **в 2.2 раза меньше параметров** и работая **более чем в 80 раз быстрее** (0.51 мс против 43.4 мс). Это делает её оптимальным кандидатом для развертывания в системах реального времени.
    
3.  **Умеренный эффект SSL-дообучения:** Дополнительное самообучение DINOv2 на целевом домене дало положительный, но небольшой прирост в точности логистической регрессии (+0.26%). Это указывает на правильность направления, но также показывает, что предобученные признаки уже являются очень сильными.
    
4.  **Практическая значимость:** Эксперимент подтверждает, что предложенный двухэтапный подход (использование признаков универсальной SSL-модели + их дистилляция в компактный классификатор) является эффективной методологией для создания точных и ресурсоэффективных решений для индустриального компьютерного зрения.
    